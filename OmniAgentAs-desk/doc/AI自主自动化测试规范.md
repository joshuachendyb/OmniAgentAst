# AI自主测试规范

**制定时间**: 2026-02-17 09:25:44  
**适用范围**: AI自动化测试 - 包括AI能够做的全部测试类型、测试分析、报告、总结的编写  
**核心原则**: 测试是为了暴露问题、解决问题、最终消灭问题

---

## 一、测试目的与范围

### 1.1 核心目标与考核标准

**测试的根本目的**:
1. **暴露问题** - 通过测试发现被测代码中的缺陷、错误、隐患
2. **解决问题** - 定位根因，实施修复
3. **消灭问题** - 验证修复，确保问题彻底解决，最终归零

**测试报告的价值**:
- 准确记录发现的问题
- 真实反映被测代码质量
- 追踪问题从发现到解决的全过程
- 最终目标：报告末尾不存在任何未解决的问题

**考核标准**（唯一标准）:
1. **问题归零** - 最终轮次必须达到: failed=0, error=0
2. **验收通过** - 用户验收时，报告中已解决的问题不能再被发现
3. **无遗留问题** - 报告结尾不得存在"建议下一步"、"待后续处理"等未解决问题的描述

**绝对禁止**:
- ❌ 掩盖或粉饰问题
- ❌ 验收时被用户发现报告中已解决的问题
- ❌ 报告末尾遗留未解决问题
- ❌ 添加"建议"、"评估"、"下一步"等无实质内容的章节

### 1.2 测试范围覆盖

本规范适用于**所有AI自主执行的自动化测试、测试分析、报告编写、总结编写**工作：

| 测试类型 | 说明 | 适用性 |
|---------|------|--------|
| **单元测试** | 函数/方法级别的最小单元测试 | ✅ 必须遵循 |
| **集成测试** | 模块间交互、接口联调测试 | ✅ 必须遵循 |
| **回归测试** | 修复后的重复验证测试 | ✅ 必须遵循 |
| **冒烟测试** | 核心功能快速验证测试 | ✅ 必须遵循 |
| **端到端测试(E2E)** | 完整业务流程自动化测试(Playwright/Selenium) | ✅ 必须遵循 |
| **API测试** | 接口契约、参数、响应验证 | ✅ 必须遵循 |
| **性能测试** | 响应时间、吞吐量基准测试 | ✅ 必须遵循 |
| **压力测试** | 高负载、并发、极限条件测试 | ✅ 必须遵循 |
| **安全测试** | 自动化漏洞扫描、注入检测 | ✅ 必须遵循 |
| **契约测试** | API契约一致性验证 | ✅ 必须遵循 |
| **兼容性测试** | 多浏览器、多环境兼容验证 | ✅ 必须遵循 |
| **代码质量测试** | 静态分析、Lint检查、规范验证 | ✅ 必须遵循 |
| **覆盖率测试** | 代码覆盖率统计与验证 | ✅ 必须遵循 |
| **依赖测试** | 第三方库版本兼容性测试 | ✅ 必须遵循 |
| **配置测试** | 不同配置参数下的行为测试 | ✅ 必须遵循 |

**明确不包括**（需要用户参与的测试）：
- ❌ **验收测试** - 由用户执行的功能验收
- ❌ **探索性测试** - 人工自由探索式测试
- ❌ **用户体验测试** - 需要人工判断的UI/UX测试
- ❌ **业务逻辑确认** - 需要业务专家确认的场景

**原则**: 只要是AI能够自主执行的自动化测试，无论类型，都必须遵循本规范。AI能做的事情，就应该做，而且要按规范做。

### 1.3 禁止行为

**关于测试目的**:
- ❌ 测试只暴露问题不解决问题
- ❌ 测试报告用于"表功"或"展示成绩"
- ❌ 掩盖问题或粉饰太平

**关于报告内容**:
- ❌ 报告末尾存在未解决的问题（必须全部解决）
- ❌ 添加"建议"、"下一步"、"待优化"等未完成的描述
- ❌ 添加无意义的分析、评估、展望章节
- ❌ 自我吹嘘（如"代码质量很好"、"测试很完善"）

---

## 二、测试执行规范

### 2.1 首轮测试

**必须做到**:
1. **发现问题** - 执行完整测试套件，记录所有失败/错误
2. **分类问题** - 明确区分测试代码问题 vs 被测代码问题
3. **立即修复测试代码问题** - 首轮测试完成后，自行修复所有测试代码问题
4. **记录被测代码问题** - 详细记录被测代码的问题、原因、位置

**禁止**:
- ❌ 首轮测试发现问题不立即修复测试代码问题
- ❌ 把测试代码问题留给后续轮次

### 2.2 多轮回归测试

**核心规则**:
- **不限制轮数** - 直到问题归零为止
- **每轮必须解决所有问题** - 不允许遗留问题到下一轮
- **追加模式记录** - 每轮测试结果追加到报告尾部，不修改已有内容
- **真实记录** - 老老实实记录，不能弄虚作假

**每轮测试必须**:
1. 执行完整测试
2. 记录失败/错误详情
3. 明确问题归属（测试代码/被测代码）
4. 修复所有问题
5. 验证修复
6. 追加记录到报告

### 2.3 测试文件与数据位置规范

**铁律**: 测试代码、测试数据、测试结果**必须**在`tests/`目录下，**严禁**在项目根目录或其他位置随意放置。

**禁止行为**（历史教训）:
- ❌ 在根目录下生成`test-xxx.js`等测试脚本
- ❌ 在根目录下放置测试数据文件
- ❌ 在根目录下生成测试报告或日志
- ❌ 在`src/`目录下混入测试代码

**必须遵守**:
- ✅ **测试代码**: `backend/tests/` 或 `tests/`
- ✅ **测试数据**: `backend/tests/data/` 或 `tests/data/`
- ✅ **测试报告**: `doc/` 目录下的测试报告文件
- ✅ **临时文件**: 使用`tempfile`模块，在临时目录创建，测试后清理

**示例目录结构**:
```
project/
├── src/                    # 被测代码（严禁放入测试代码）
├── tests/                  # 测试代码（必须全部在此）
│   ├── __init__.py
│   ├── conftest.py
│   ├── test_module1.py
│   ├── test_module2.py
│   └── data/               # 测试数据
│       ├── test_input.txt
│       └── expected_output.txt
├── doc/                    # 测试报告
│   └── 测试报告.md
└── README.md
```

---

## 三、问题分类与标记

### 3.1 问题类型定义

| 类型 | 定义 | 颜色标记 | 责任方 |
|------|------|---------|--------|
| **测试代码问题** | 测试工具、测试逻辑、测试数据的问题 | 🟡 黄色 | AI自身 |
| **被测代码问题** | 被测功能、业务逻辑、实现缺陷 | 🔴 红色 | 需报告 |
| **第三方依赖** | 外部库、框架、环境配置问题 | ⚪ 灰色 | 记录即可 |

### 3.2 处理优先级

1. **首轮测试后立即修复** - 所有🟡测试代码问题，不写入回归测试报告
2. **详细记录并修复** - 所有🔴被测代码问题，必须完整记录修复过程
3. **简单记录** - ⚪第三方依赖问题，记录解决方式即可

---

## 四、问题编号规范

### 4.1 编号格式

**[测试类型][问题类型]-[项目标识]-[3位递增序号]**

### 4.2 编号组成部分

#### 第1部分：[测试类型][问题类型]（4位）

**测试类型**（第1-2位）：
| 代码 | 含义 | 说明 |
|------|------|------|
| **UT** | Unit Test | 单元测试 |
| **IT** | Integration Test | 集成测试 |
| **RT** | Regression Test | 回归测试 |
| **PT** | Performance Test | 性能测试 |
| **ST** | Security Test | 安全测试 |
| **CT** | Contract Test | 契约测试 |
| **ET** | End-to-End Test | 端到端测试 |

**问题类型**（第3-4位）：
| 代码 | 含义 | 颜色 | 说明 |
|------|------|------|------|
| **TC** | Test Code | 🟡 黄色 | 测试代码问题（AI自身问题）|
| **BC** | Business Code | 🔴 红色 | 被测代码问题（需报告）|
| **DP** | Dependency | ⚪ 灰色 | 第三方依赖问题 |

#### 第2部分：[项目标识]（2-4位，可选但建议填写）

表示项目阶段、功能模块、特殊事件或范围：

**项目阶段**：
| 代码 | 含义 | 说明 |
|------|------|------|
| **P11** | Phase 1.1 | 阶段1.1 |
| **P12** | Phase 1.2 | 阶段1.2 |
| **P13** | Phase 1.3 | 阶段1.3 |
| **P20** | Phase 2.0 | 阶段2.0 |

**功能模块**（中文缩写）：
| 代码 | 含义 | 说明 |
|------|------|------|
| **WJ** | 文件 | 文件操作模块 |
| **YH** | 用户 | 用户管理模块 |
| **QX** | 权限 | 权限控制模块 |
| **SJ** | 审计 | 审计日志模块 |
| **XT** | 系统 | 系统核心模块 |
| **API** | API | API接口模块 |

**特殊事件/范围**：
| 代码 | 含义 | 说明 |
|------|------|------|
| **W1** | Wave 1 | 第1波修复 |
| **W2** | Wave 2 | 第2波修复 |
| **W5** | Wave 5 | 第5波修复 |
| **BC** | 波次 | 泛指波次修复 |
| **HG** | 回归 | 回归测试专项 |

#### 第3部分：[3位递增序号]（3位）

- 全局唯一递增，从001开始
- 同一测试项目中不重复
- 即使前面问题已修复，序号不回收

### 4.3 编号示例

```
UTBC-P13-001    - 单元测试、被测代码问题、阶段1.3、第1个问题
RTTC-W5-002     - 回归测试、测试代码问题、Wave5、第2个问题
ITBC-WJ-003     - 集成测试、被测代码问题、文件模块、第3个问题
UTBC-P13-WJ-004 - 单元测试、被测代码问题、阶段1.3、文件模块、第4个问题
PTDP-P12-001    - 性能测试、依赖问题、阶段1.2、第1个问题
ETBC-HG-005     - E2E测试、被测代码问题、回归测试、第5个问题
```

### 4.4 编号使用规范

1. **问题标题必须使用编号**
   ```markdown
   ### 问题 UTBC-P13-001: test_agent_rollback_no_session <span style="color:red">(🔴 被测代码问题)</span>
   ```

2. **第2部分可选但建议填写** - 便于问题追踪和分类统计

3. **第2部分可叠加** - 如"P13-WJ"表示阶段1.3的文件模块问题

4. **全局序号递增** - 所有问题共用一套3位序号（001-999）

5. **同一项目中不重复** - 即使不同阶段也不能重复使用相同完整编号

---

## 五、测试报告与总结编写规范

**重要说明**: 测试报告和总结的编写是AI的核心职责之一，必须严格按照本规范执行。

### 5.1 报告编写的根本原则

**报告的目的**:
1. **暴露问题** - 如实记录测试中发现的全部问题
2. **反映质量** - 真实呈现被测代码的当前质量状态
3. **追踪闭环** - 记录问题从发现到解决的完整过程
4. **证明归零** - 最终证明所有问题已解决，达到可交付状态

**报告编写铁律**:
- ✅ **只记录事实** - 问题是什么、为什么、怎么修、是否解决
- ✅ **必须闭环** - 每个问题都有明确的修复和验证结果
- ✅ **零遗留** - 报告末尾不存在任何未解决的问题
- ❌ **禁止粉饰** - 不掩盖、不缩小、不转移问题
- ❌ **禁止表功** - 不吹嘘成绩、不自我表扬
- ❌ **禁止建议** - 不写"建议"、"下一步"、"待优化"等未完成事项

### 5.2 报告内容（只保留必要信息）

**必须包含**:
1. **执行时间** - 实际系统时间（不准估计）
2. **测试范围** - 测试文件、模块、场景
3. **问题清单** - 每个问题的详细描述、归属类别、修复方式
4. **修复代码变更** - 具体的代码diff或变更说明
5. **验证结果** - 修复后的测试结果（必须显示问题已解决）

**报告结尾要求**:
- ✅ 最终结论必须明确：所有问题已修复，failed=0, error=0
- ✅ 不得存在未解决问题的描述
- ✅ 不得出现"建议下一步"、"待优化"、"需后续处理"等字样

**禁止添加**:
- ❌ "代码质量很好"等自我吹嘘
- ❌ "建议"、"评估"、"分析"、"下一步"等无意义章节
- ❌ "部分完成"、"基本完成"等模糊表述
- ❌ 与问题无关的背景介绍
- ❌ 假设性、推测性内容

### 5.3 报告编写方法

```markdown
#### 问题 [UTBC-P13-001格式编号]: [测试名称] [颜色标记]

**现象**: [具体的错误信息/失败表现]

**归属类别**: [🟡 测试代码问题 / 🔴 被测代码问题 / ⚪ 第三方依赖]

**根因分析**: [具体原因，不说废话]

**修复代码**:
```python
# 具体的代码变更
```

**文件**: [文件路径] [行号范围]

**验证**: [修复后的测试结果]
```

**写作风格**:
- **客观陈述** - 只写事实，不写感受（如"我很认真地测试了"）
- **具体明确** - 写具体数字、具体文件、具体行号（如"第156行"而非"某处"）
- **简洁直接** - 不说废话，不绕弯子
- **闭环思维** - 每个问题都必须有"现象→原因→修复→验证"完整链条

**报告结构模板**:
```markdown
# [测试类型]报告

**执行时间**: [真实系统时间]
**测试范围**: [具体文件/模块]
**执行人**: AI助手

## 一、执行结果总览

| 指标 | 数值 | 状态 |
|------|------|------|
| 总测试数 | X | - |
| 通过 | X | ✅ |
| 失败 | X | [🔴问题数量] |
| 错误 | X | [🔴问题数量] |
| 跳过 | X | ℹ️ |

## 二、问题清单与修复

### 问题 UTBC-P13-001: [问题简述] [🟡/🔴颜色标记]

**现象**: [具体错误信息]

**归属类别**: [测试代码/被测代码/第三方依赖]

**根因分析**: [具体原因，一句话说清楚]

**修复代码**:
```python
# 具体的代码变更（diff格式或代码块）
```

**文件**: [文件路径] [行号]

**验证**: [修复后测试结果，必须证明已解决]

## 三、回归测试记录

### 第1轮回归测试
[按追加格式记录]

### 第2轮回归测试
[按追加格式记录]

...

## 四、最终结论

- ✅ 所有🔴被测代码问题已修复 (X/X)
- ✅ 所有🟡测试代码问题已修复 (X/X)
- ✅ 最终测试状态: X passed, 0 failed, 0 error
- ✅ **问题已归零，报告结束**

**报告完成时间**: [真实系统时间]
```

### 5.4 回归测试追加格式

```markdown
---

## 第N轮回归测试（**追加记录**）

### 执行时间
[实际系统时间，不准估计]

### 测试执行结果
```
[pytest输出结果]
```

### 修复的问题清单

| 序号 | 测试名称 | 归属类别 | 修复方式 | 状态 |
|------|---------|---------|---------|------|
| 1 | test_xxx | [颜色标记] | [修复简述] | ✅ |

### 修复详情

#### 修复1: test_xxx [颜色标记]
[按5.4格式记录]

### 结论
- [颜色标记] **[类型]问题已修复** (X/X)
- **最终通过率**: X%

**第N轮记录追加时间**: [实际系统时间]
**执行状态**: [完成/进行中]
```

---

## 六、测试方法与工具规范

### 6.1 系统性测试方法

**分层测试策略**：

| 层级 | 测试范围 | 目标 | 示例 |
|------|---------|------|------|
| **L1 - 单元层** | 单个函数/方法 | 验证最小单元逻辑正确 | `test_read_file_success()` |
| **L2 - 组件层** | 类/模块内部交互 | 验证组件内部协作 | `test_file_tools_with_safety()` |
| **L3 - 集成层** | 模块间接口 | 验证模块间数据传递 | `test_adapter_message_conversion()` |
| **L4 - 系统层** | 完整业务流程 | 验证端到端功能 | `test_agent_full_workflow()` |

**测试覆盖原则**：
1. **全面覆盖** - 所有公共API、核心逻辑、边界条件必须有测试
2. **场景覆盖** - 正常场景、异常场景、边界场景都必须测试
3. **数据覆盖** - 有效数据、无效数据、空值、极端值都必须验证

**性能监控要求**：
- 测试执行时监控响应时间
- 记录性能基准数据
- 发现性能退化立即标记

### 6.2 工具化测试流程

**自动化测试工具开发原则**：

1. **工具即代码**
   - 测试工具本身必须有测试
   - 测试工具代码遵循同样规范
   - 测试工具版本管理与被测代码同步

2. **工具分类**
   ```
   tests/
   ├── tools/              # 测试辅助工具
   │   ├── data_generator.py    # 测试数据生成器
   │   ├── mock_factory.py      # Mock对象工厂
   │   └── performance_monitor.py # 性能监控工具
   ├── conftest.py         # pytest fixtures
   └── ...
   ```

3. **工具使用规范**
   - 数据生成器：统一生成测试数据，避免硬编码
   - Mock工厂：标准化Mock创建，避免重复代码
   - 性能监控：自动记录测试耗时，生成性能报告

**工具开发禁止**：
- ❌ 测试工具代码不写测试
- ❌ 测试工具随意放置在项目根目录
- ❌ 测试工具产生的结果不清理

---

## 七、时间戳规范

### 7.1 必须获取真实系统时间

**命令**:
```bash
# Linux/Mac
date "+%Y-%m-%d %H:%M:%S"

# Windows PowerShell
Get-Date -Format "yyyy-MM-dd HH:mm:ss"
```

### 7.2 禁止行为
- ❌ 估计时间（如"大概9点"）
- ❌ 使用固定时间模板
- ❌ 事后补写时间

---

## 八、修复验证规范

### 8.1 修复后必须验证

每轮修复后必须:
1. 重新运行完整测试套件
2. 确认之前失败的问题已解决
3. 确认没有引入新问题
4. 记录验证结果

### 8.2 问题归零标准

**最终轮次必须满足**:
```
passed: X
failed: 0
error: 0
skipped: [允许，需说明原因]
```

**未完成标准**:
- 只要还有 failed > 0 或 error > 0，就必须继续下一轮
- 不能因"差不多行了"停止测试

---

## 九、经验教训（来自本次测试）

### 9.1 错误做法（已纠正）

1. **首轮测试不修复测试代码问题**
   - ❌ 错误：首轮发现测试代码问题，留给后续轮次
   - ✅ 正确：首轮后立即修复所有测试代码问题

2. **时间戳瞎估计**
   - ❌ 错误：写"09:50"等估计时间
   - ✅ 正确：执行 `date` 命令获取真实时间

3. **报告内容自我吹嘘**
   - ❌ 错误：添加"代码质量很好"、"期望建议"等内容
   - ✅ 正确：只记录问题、修复、验证结果

4. **回归测试插入而非追加**
   - ❌ 错误：把新轮次内容插入已有章节
   - ✅ 正确：追加到文档尾部

5. **不区分问题类型**
   - ❌ 错误：混为一谈，不明确标记
   - ✅ 正确：测试代码问题标黄，被测代码问题标红

### 9.2 正确做法

1. **首轮测试后立即修复测试代码问题**
   - 测试代码问题是AI自身写的有问题，立即自行修复
   - 修复后再进行下一轮，不让测试代码问题进入回归报告

2. **老老实实记录**
   - 失败就是失败，错误就是错误
   - 不掩盖、不粉饰、不弄虚作假

3. **问题必须归零**
   - 不管多少轮，直到 failed=0, error=0
   - 没有"差不多"，只有"完全解决"

4. **报告只保留必要信息**
   - 问题是什么
   - 为什么（根因）
   - 怎么修复（代码变更）
   - 是否验证通过

---

## 十、执行检查清单

每次测试工作前自检：

- [ ] 是否获取了真实系统时间？
- [ ] 是否理解测试要暴露问题、解决问题、最终消灭问题？
- [ ] 是否准备好区分测试代码/被测代码问题？
- [ ] 是否知道测试代码问题要自行修复不报告？
- [ ] 是否清楚报告只能追加不能插入？
- [ ] 是否明白报告末尾不能存在未解决的问题？

---

## 十一、惩罚机制

违反以下任意一条，接受惩罚：

| 违规行为 | 惩罚 |
|---------|------|
| 时间戳瞎估计 | 重新获取真实时间并修正 |
| 测试代码问题不立即修复 | 立即停止，修复后再继续 |
| 回归测试插入而非追加 | 删除插入内容，重新追加 |
| 报告添加自我吹嘘 | 删除相关内容 |
| 问题未归零就结束 | 继续测试直到归零 |
| 弄虚作假 | 重新执行完整测试流程 |

---

**规范生效时间**: 2026-02-17 09:25:44  
**适用范围**: AI自动化测试 - 包括AI能够做的全部测试类型、测试分析、报告、总结的编写  
**核心原则**: **暴露问题 → 解决问题 → 消灭问题，报告末尾零问题**
