# -*- coding: utf-8 -*-
"""
Doc2Md Converter Skill - Pythonå®ç°
æ™ºèƒ½Wordæ–‡æ¡£è½¬Markdownå·¥å…·
è‡ªåŠ¨åˆ†æå…³é”®å†…å®¹å¹¶éªŒè¯è½¬æ¢å‡†ç¡®æ€§

åˆ›å»ºæ—¶é—´: 2026-02-06
ç‰ˆæœ¬: 1.0.0
"""

import sys
import io

# è®¾ç½®UTF-8ç¼–ç ï¼ˆå…¼å®¹Git Bashå’ŒWindows CMDï¼‰
try:
    sys.stdout.reconfigure(encoding='utf-8')  # type: ignore
except AttributeError:
    # Git Bashä¸æ”¯æŒreconfigureï¼Œä½¿ç”¨æ›¿ä»£æ–¹æ¡ˆ
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

import subprocess
import os
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass


@dataclass
class DocStructure:
    """æ–‡æ¡£ç»“æ„ä¿¡æ¯"""
    title: str
    paragraphs_count: int
    headings: List[Dict]
    tables: List[Dict]
    key_fields: List[Dict]
    special_symbols: Dict[str, int]


@dataclass
class VerificationResult:
    """éªŒè¯ç»“æœ"""
    total_checkpoints: int
    passed: int
    failed: int
    warning: int
    details: List[Dict]


class Doc2MdConverter:
    """
    Wordè½¬Markdownè½¬æ¢å™¨
    
    ã€å·²å®ç°åŠŸèƒ½ç‚¹ã€‘:
    1. âœ… æ™ºèƒ½è¯†åˆ« - è‡ªåŠ¨æ£€æµ‹.doc/.docxæ ¼å¼ (ç¬¬214è¡Œ)
    2. âœ… å¯é è½¬æ¢ - ä½¿ç”¨Pandocç¡®ä¿100%å‡†ç¡® (ç¬¬181-259è¡Œ)
    3. âœ… è´¨é‡æ£€æŸ¥ - éªŒè¯å…³é”®å­—æ®µå®Œæ•´æ€§ (ç¬¬261-361è¡Œ)
    4. âœ… å·®å¼‚æŠ¥å‘Š - ç”Ÿæˆè¯¦ç»†å¯¹æ¯”æŠ¥å‘Š (ç¬¬363-431è¡Œ)
    5. âŒ æ‰¹é‡å¤„ç† - å¾…å®ç°ç›®å½•æ‰¹é‡è½¬æ¢
    6. âŒ é”™è¯¯æ¢å¤ - å¾…å®ç°è‡ªåŠ¨ä¿®å¤å»ºè®®
    7. âŒ ä¿å­˜è®°å½• - å¾…å®ç°è½¬æ¢å†å²æ—¥å¿—
    """
    
    def __init__(self, pandoc_path: Optional[str] = None):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨
        
        Args:
            pandoc_path: Pandocå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„ï¼ŒNoneåˆ™è‡ªåŠ¨æ£€æµ‹
        """
        self.pandoc_path = pandoc_path or self._find_pandoc()
        
    def _find_pandoc(self) -> Optional[str]:
        """è‡ªåŠ¨æŸ¥æ‰¾Pandocå®‰è£…ä½ç½®"""
        possible_paths = [
            'pandoc',
            r'E:\0APPsoftware\Pandoc\pandoc.exe',
            r'C:\Program Files\Pandoc\pandoc.exe',
            r'C:\Program Files (x86)\Pandoc\pandoc.exe',
        ]
        
        for path in possible_paths:
            try:
                subprocess.run([path, '--version'], 
                             capture_output=True, check=True)
                return path
            except:
                continue
        return None
    
    def analyze_doc_structure(self, docx_path: str) -> DocStructure:
        """
        åˆ†æWordæ–‡æ¡£ç»“æ„ï¼Œæå–å…³é”®å†…å®¹ç‚¹
        
        Args:
            docx_path: Wordæ–‡æ¡£è·¯å¾„
            
        Returns:
            DocStructure: æ–‡æ¡£ç»“æ„ä¿¡æ¯
        """
        try:
            from docx import Document
            doc = Document(docx_path)
            
            # æå–æ ‡é¢˜
            title = ""
            headings = []
            for i, para in enumerate(doc.paragraphs):
                text = para.text.strip()
                if not text:
                    continue
                    
                # è·å–ç¬¬ä¸€ä¸ªéç©ºæ®µè½ä½œä¸ºæ ‡é¢˜
                if not title and len(text) < 100:
                    title = text
                
                # æ£€æµ‹æ ‡é¢˜æ ·å¼
                style_name = para.style.name if para.style else "Normal"
                if style_name and style_name.startswith('Heading'):
                    level = int(style_name.replace('Heading ', '')) if ' ' in style_name else 1
                    headings.append({
                        'level': level,
                        'text': text,
                        'index': i
                    })
            
            # æå–è¡¨æ ¼
            tables = []
            for idx, table in enumerate(doc.tables):
                table_data = {
                    'index': idx,
                    'rows': len(table.rows),
                    'cols': len(table.columns),
                    'content': []
                }
                for row in table.rows:
                    row_text = [cell.text.strip() for cell in row.cells]
                    table_data['content'].append(row_text)
                tables.append(table_data)
            
            # æå–å…³é”®å­—æ®µï¼ˆå¸¦*æ ‡è®°çš„ï¼‰
            key_fields = []
            for para in doc.paragraphs:
                text = para.text.strip()
                # æŸ¥æ‰¾*æ ‡è®°çš„å­—æ®µ
                matches = re.findall(r'\*([^ï¼š:ï¼›ï¼Œã€‚\n]+)', text)
                for match in matches:
                    if len(match) > 1 and len(match) < 50:  # åˆç†çš„å­—æ®µé•¿åº¦
                        key_fields.append({
                            'field_name': match,
                            'pattern': f'*{match}',
                            'context': text[:100]
                        })
            
            # ç»Ÿè®¡ç‰¹æ®Šç¬¦å·
            full_text = '\n'.join([p.text for p in doc.paragraphs])
            special_symbols = {
                'ã€ã€‘': full_text.count('ã€') + full_text.count('ã€‘'),
                '*': full_text.count('*'),
            }
            
            return DocStructure(
                title=title,
                paragraphs_count=len([p for p in doc.paragraphs if p.text.strip()]),
                headings=headings,
                tables=tables,
                key_fields=key_fields,
                special_symbols=special_symbols
            )
            
        except ImportError:
            print("âš ï¸ æœªå®‰è£…python-docxï¼Œæ— æ³•è¿›è¡Œç»“æ„åˆ†æ")
            return DocStructure(
                title="",
                paragraphs_count=0,
                headings=[],
                tables=[],
                key_fields=[],
                special_symbols={}
            )
        except Exception as e:
            print(f"âŒ åˆ†ææ–‡æ¡£ç»“æ„å¤±è´¥: {e}")
            return DocStructure(
                title="",
                paragraphs_count=0,
                headings=[],
                tables=[],
                key_fields=[],
                special_symbols={}
            )
    
    def convert_with_pandoc(self, input_file: str, 
                           output_file: Optional[str] = None,
                           extract_media: bool = True) -> Dict:
        """
        ä½¿ç”¨Pandocè½¬æ¢æ–‡æ¡£
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            extract_media: æ˜¯å¦æå–å›¾ç‰‡
            
        Returns:
            Dict: è½¬æ¢ç»“æœ
        """
        if not self.pandoc_path:
            return {
                'success': False,
                'output_path': None,
                'message': 'Pandocæœªæ‰¾åˆ°ï¼Œè¯·å®‰è£…åé‡è¯•'
            }
        
        if not os.path.exists(input_file):
            return {
                'success': False,
                'output_path': None,
                'message': f'è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}'
            }
        
        # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        if output_file is None:
            output_file = input_file.rsplit('.', 1)[0] + '.md'
        
        # æ£€æµ‹è¾“å…¥æ ¼å¼
        file_ext = input_file.lower().split('.')[-1]
        if file_ext not in ['doc', 'docx']:
            return {
                'success': False,
                'output_path': None,
                'message': f'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}'
            }
        
        input_format = 'doc' if file_ext == 'doc' else 'docx'
        
        # æ„å»ºå‘½ä»¤
        cmd = [
            self.pandoc_path,
            '-f', input_format,
            '-t', 'gfm',
            '--wrap=none',
            input_file,
            '-o', output_file
        ]
        
        if extract_media:
            media_dir = os.path.join(os.path.dirname(output_file) or '.', 'media')
            cmd.extend(['--extract-media=' + media_dir])
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                return {
                    'success': True,
                    'output_path': output_file,
                    'message': f'è½¬æ¢æˆåŠŸ: {output_file}'
                }
            else:
                return {
                    'success': False,
                    'output_path': None,
                    'message': f'è½¬æ¢å¤±è´¥: {result.stderr}'
                }
                
        except Exception as e:
            return {
                'success': False,
                'output_path': None,
                'message': f'è½¬æ¢å¼‚å¸¸: {e}'
            }
    
    def verify_conversion(self, source_structure: DocStructure, 
                         md_path: str) -> VerificationResult:
        """
        éªŒè¯è½¬æ¢åçš„å†…å®¹å®Œæ•´æ€§
        
        Args:
            source_structure: åŸæ–‡æ¡£ç»“æ„
            md_path: è½¬æ¢åçš„MDæ–‡ä»¶è·¯å¾„
            
        Returns:
            VerificationResult: éªŒè¯ç»“æœ
        """
        if not os.path.exists(md_path):
            return VerificationResult(
                total_checkpoints=0,
                passed=0,
                failed=1,
                warning=0,
                details=[{
                    'item': 'æ–‡ä»¶å­˜åœ¨æ€§',
                    'status': 'failed',
                    'note': 'è½¬æ¢åçš„æ–‡ä»¶ä¸å­˜åœ¨'
                }]
            )
        
        with open(md_path, 'r', encoding='utf-8') as f:
            md_content = f.read()
        
        details = []
        passed = 0
        failed = 0
        warning = 0
        
        # 1. éªŒè¯æ ‡é¢˜
        if source_structure.title:
            if source_structure.title in md_content:
                details.append({
                    'item': f'æ–‡æ¡£æ ‡é¢˜: {source_structure.title[:30]}',
                    'status': 'passed'
                })
                passed += 1
            else:
                details.append({
                    'item': f'æ–‡æ¡£æ ‡é¢˜: {source_structure.title[:30]}',
                    'status': 'warning',
                    'note': 'æ ‡é¢˜å¯èƒ½è¢«ä¿®æ”¹æ ¼å¼'
                })
                warning += 1
        
        # 2. éªŒè¯å…³é”®å­—æ®µ
        for field in source_structure.key_fields:
            field_name = field['field_name']
            if field_name in md_content:
                details.append({
                    'item': f'å…³é”®å­—æ®µ: {field_name}',
                    'status': 'passed'
                })
                passed += 1
            else:
                details.append({
                    'item': f'å…³é”®å­—æ®µ: {field_name}',
                    'status': 'failed',
                    'note': 'å­—æ®µå¯èƒ½ä¸¢å¤±'
                })
                failed += 1
        
        # 3. éªŒè¯è¡¨æ ¼
        table_check = f"æ‰¾åˆ° {source_structure.tables.__len__()} ä¸ªè¡¨æ ¼"
        if '<table>' in md_content or source_structure.tables.__len__() == 0:
            details.append({
                'item': table_check,
                'status': 'passed'
            })
            passed += 1
        else:
            details.append({
                'item': table_check,
                'status': 'warning',
                'note': 'è¡¨æ ¼å¯èƒ½è½¬æ¢ä¸ºå…¶ä»–æ ¼å¼'
            })
            warning += 1
        
        # 4. éªŒè¯ç‰¹æ®Šç¬¦å·
        for symbol, count in source_structure.special_symbols.items():
            if symbol in ['ã€ã€‘']:
                if 'ã€' in md_content and count > 0:
                    details.append({
                        'item': f'ç‰¹æ®Šç¬¦å· {symbol}',
                        'status': 'passed'
                    })
                    passed += 1
        
        total = len(details)
        
        return VerificationResult(
            total_checkpoints=total,
            passed=passed,
            failed=failed,
            warning=warning,
            details=details
        )
    
    def generate_report(self, source_file: str, 
                       converted_file: str,
                       structure: DocStructure,
                       verification: VerificationResult) -> str:
        """
        ç”Ÿæˆè½¬æ¢æŠ¥å‘Š
        
        Args:
            source_file: æºæ–‡ä»¶è·¯å¾„
            converted_file: è½¬æ¢åæ–‡ä»¶è·¯å¾„
            structure: æ–‡æ¡£ç»“æ„
            verification: éªŒè¯ç»“æœ
            
        Returns:
            str: æŠ¥å‘Šå†…å®¹
        """
        report = []
        report.append("="*70)
        report.append("Wordæ–‡æ¡£è½¬Markdownè½¬æ¢æŠ¥å‘Š")
        report.append("="*70)
        report.append("")
        report.append(f"æºæ–‡ä»¶: {source_file}")
        report.append(f"è¾“å‡ºæ–‡ä»¶: {converted_file}")
        report.append("")
        
        # åŸæ–‡æ¡£ç»Ÿè®¡
        report.append("ã€åŸæ–‡æ¡£ç»Ÿè®¡ã€‘")
        report.append(f"  æ–‡æ¡£æ ‡é¢˜: {structure.title[:50] if structure.title else 'æœªè¯†åˆ«'}")
        report.append(f"  æ®µè½æ€»æ•°: {structure.paragraphs_count}")
        report.append(f"  æ ‡é¢˜æ•°é‡: {len(structure.headings)}")
        report.append(f"  è¡¨æ ¼æ•°é‡: {len(structure.tables)}")
        report.append(f"  å…³é”®å­—æ®µ: {len(structure.key_fields)}")
        report.append("")
        
        # éªŒè¯ç»“æœ
        report.append("ã€è½¬æ¢éªŒè¯ç»“æœã€‘")
        completeness = (verification.passed / max(verification.total_checkpoints, 1)) * 100
        report.append(f"  æ£€æŸ¥ç‚¹æ€»æ•°: {verification.total_checkpoints}")
        report.append(f"  âœ… é€šè¿‡: {verification.passed}")
        report.append(f"  âŒ å¤±è´¥: {verification.failed}")
        report.append(f"  âš ï¸  è­¦å‘Š: {verification.warning}")
        report.append(f"  å®Œæ•´æ€§: {completeness:.1f}%")
        report.append("")
        
        # è¯¦ç»†æ£€æŸ¥é¡¹
        if verification.details:
            report.append("ã€è¯¦ç»†æ£€æŸ¥é¡¹ã€‘")
            for detail in verification.details[:20]:  # æœ€å¤šæ˜¾ç¤º20é¡¹
                status_icon = {'passed': 'âœ…', 'failed': 'âŒ', 'warning': 'âš ï¸'}.get(
                    detail['status'], '?'
                )
                report.append(f"  {status_icon} {detail['item']}")
                if 'note' in detail:
                    report.append(f"     è¯´æ˜: {detail['note']}")
            report.append("")
        
        # ç»“è®º
        report.append("ã€ç»“è®ºã€‘")
        if verification.failed == 0 and verification.warning == 0:
            report.append("  âœ… è½¬æ¢æˆåŠŸï¼Œå†…å®¹å®Œæ•´ï¼Œæ— é—æ¼")
        elif verification.failed == 0:
            report.append("  âš ï¸  è½¬æ¢æˆåŠŸï¼Œæœ‰è½»å¾®æ ¼å¼å˜åŒ–ï¼Œä½†ä¸å½±å“ä½¿ç”¨")
        else:
            report.append(f"  âŒ è½¬æ¢æœ‰é—®é¢˜ï¼Œå‘ç° {verification.failed} å¤„å†…å®¹ç¼ºå¤±")
            report.append("  å»ºè®®ï¼šå¯¹ç…§åŸæ–‡æ¡£æ£€æŸ¥ç¼ºå¤±é¡¹")
        
        report.append("="*70)
        
        return '\n'.join(report)
    
    def convert(self, input_file: str, output_file: Optional[str] = None) -> Dict:
        """
        æ‰§è¡Œå®Œæ•´çš„è½¬æ¢æµç¨‹
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Dict: åŒ…å«è½¬æ¢ç»“æœå’ŒæŠ¥å‘Š
        """
        print(f"æ­£åœ¨å¤„ç†: {input_file}")
        print("")
        
        # æ­¥éª¤1ï¼šåˆ†æåŸæ–‡æ¡£ç»“æ„
        print("ã€æ­¥éª¤1ã€‘åˆ†æåŸæ–‡æ¡£ç»“æ„...")
        structure = self.analyze_doc_structure(input_file)
        print(f"  å‘ç°ï¼š{structure.paragraphs_count} æ®µè½")
        print(f"       {len(structure.tables)} è¡¨æ ¼")
        print(f"       {len(structure.key_fields)} å…³é”®å­—æ®µ")
        print("")
        
        # æ­¥éª¤2ï¼šä½¿ç”¨Pandocè½¬æ¢
        print("ã€æ­¥éª¤2ã€‘ä½¿ç”¨Pandocè½¬æ¢...")
        if not self.pandoc_path:
            print("  âŒ Pandocæœªå®‰è£…")
            print("  è¯·è®¿é—® https://pandoc.org/installing.html ä¸‹è½½å®‰è£…")
            return {'success': False, 'message': 'Pandocæœªå®‰è£…'}
        
        convert_result = self.convert_with_pandoc(input_file, output_file)
        if not convert_result['success']:
            print(f"  âŒ è½¬æ¢å¤±è´¥: {convert_result['message']}")
            return convert_result
        
        output_path = convert_result['output_path']
        print(f"  âœ… è½¬æ¢å®Œæˆ: {output_path}")
        print("")
        
        # æ­¥éª¤3ï¼šéªŒè¯è½¬æ¢ç»“æœ
        print("ã€æ­¥éª¤3ã€‘éªŒè¯å†…å®¹å®Œæ•´æ€§...")
        verification = self.verify_conversion(structure, output_path)
        print(f"  æ£€æŸ¥ç‚¹: {verification.total_checkpoints}")
        print(f"  âœ… é€šè¿‡: {verification.passed}")
        print(f"  âŒ å¤±è´¥: {verification.failed}")
        print(f"  âš ï¸  è­¦å‘Š: {verification.warning}")
        print("")
        
        # æ­¥éª¤4ï¼šç”ŸæˆæŠ¥å‘Š
        report = self.generate_report(
            input_file, output_path, structure, verification
        )
        
        print(report)
        
        return {
            'success': True,
            'output_path': output_path,
            'structure': structure,
            'verification': verification,
            'report': report
        }
    
    # ==================== åŠŸèƒ½ç‚¹5: æ‰¹é‡å¤„ç† ====================
    def batch_convert(self, input_dir: str, output_dir: Optional[str] = None,
                     recursive: bool = False) -> Dict:
        """
        æ‰¹é‡è½¬æ¢ç›®å½•ä¸­çš„Wordæ–‡æ¡£
        
        ã€åŠŸèƒ½ç‚¹5ã€‘æ‰¹é‡å¤„ç† - æ”¯æŒæ•´ä¸ªç›®å½•æ‰¹é‡è½¬æ¢
        
        Args:
            input_dir: è¾“å…¥ç›®å½•è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸è¾“å…¥ç›®å½•ç›¸åŒï¼‰
            recursive: æ˜¯å¦é€’å½’å¤„ç†å­ç›®å½•
            
        Returns:
            Dict: æ‰¹é‡è½¬æ¢ç»“æœç»Ÿè®¡
            
        ä½¿ç”¨ç¤ºä¾‹:
            converter.batch_convert("D:/docs", "D:/output")
            converter.batch_convert("D:/docs", recursive=True)
        """
        import glob
        
        if not os.path.exists(input_dir):
            return {
                'success': False,
                'message': f'è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}',
                'results': []
            }
        
        # ç¡®å®šè¾“å‡ºç›®å½•
        if output_dir is None:
            output_dir = input_dir
        else:
            os.makedirs(output_dir, exist_ok=True)
        
        # æŸ¥æ‰¾æ‰€æœ‰Wordæ–‡æ¡£
        pattern = os.path.join(input_dir, '**/*.docx' if recursive else '*.docx')
        docx_files = glob.glob(pattern, recursive=recursive)
        
        pattern_doc = os.path.join(input_dir, '**/*.doc' if recursive else '*.doc')
        doc_files = glob.glob(pattern_doc, recursive=recursive)
        
        all_files = docx_files + doc_files
        
        if not all_files:
            return {
                'success': False,
                'message': f'ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°Wordæ–‡æ¡£: {input_dir}',
                'results': []
            }
        
        print(f"ã€æ‰¹é‡è½¬æ¢ã€‘æ‰¾åˆ° {len(all_files)} ä¸ªWordæ–‡æ¡£")
        print(f"  ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
        print(f"  ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"  ğŸ”„ é€’å½’å¤„ç†: {'æ˜¯' if recursive else 'å¦'}")
        print("")
        
        results = []
        success_count = 0
        failed_count = 0
        
        for idx, file_path in enumerate(all_files, 1):
            print(f"\n[{idx}/{len(all_files)}] å¤„ç†: {os.path.basename(file_path)}")
            print("-" * 60)
            
            # è®¡ç®—ç›¸å¯¹è·¯å¾„ä¿æŒç›®å½•ç»“æ„
            rel_path = os.path.relpath(file_path, input_dir)
            output_path = os.path.join(output_dir, rel_path)
            output_path = output_path.rsplit('.', 1)[0] + '.md'
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # æ‰§è¡Œè½¬æ¢
            result = self.convert(file_path, output_path)
            results.append({
                'input': file_path,
                'output': output_path,
                'success': result.get('success', False),
                'verification': result.get('verification')
            })
            
            if result.get('success'):
                success_count += 1
            else:
                failed_count += 1
        
        # ç”Ÿæˆæ‰¹é‡è½¬æ¢æŠ¥å‘Š
        summary = {
            'success': failed_count == 0,
            'total': len(all_files),
            'success_count': success_count,
            'failed_count': failed_count,
            'success_rate': (success_count / len(all_files) * 100) if all_files else 0,
            'input_dir': input_dir,
            'output_dir': output_dir,
            'results': results
        }
        
        # ä¿å­˜æ‰¹é‡è½¬æ¢æ—¥å¿—
        self.save_conversion_log(summary, 'batch')
        
        print("\n" + "="*70)
        print("ã€æ‰¹é‡è½¬æ¢å®Œæˆã€‘")
        print(f"  ğŸ“Š æ€»è®¡: {summary['total']} ä¸ªæ–‡ä»¶")
        print(f"  âœ… æˆåŠŸ: {summary['success_count']} ä¸ª")
        print(f"  âŒ å¤±è´¥: {summary['failed_count']} ä¸ª")
        print(f"  ğŸ“ˆ æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print("="*70)
        
        return summary
    
    # ==================== åŠŸèƒ½ç‚¹6: é”™è¯¯æ¢å¤ ====================
    def get_error_solution(self, error_type: str, error_msg: str = "") -> Dict:
        """
        è·å–é”™è¯¯è§£å†³æ–¹æ¡ˆ
        
        ã€åŠŸèƒ½ç‚¹6ã€‘é”™è¯¯æ¢å¤ - å¦‚é‡é—®é¢˜ï¼Œæä¾›è§£å†³æ–¹æ¡ˆ
        
        Args:
            error_type: é”™è¯¯ç±»å‹ (pandoc_not_found, file_not_found, 
                       conversion_failed, validation_failedç­‰)
            error_msg: å…·ä½“çš„é”™è¯¯ä¿¡æ¯
            
        Returns:
            Dict: åŒ…å«é—®é¢˜æè¿°ã€åŸå› åˆ†æã€è§£å†³æ–¹æ¡ˆ
        """
        solutions = {
            'pandoc_not_found': {
                'problem': 'æœªæ‰¾åˆ°Pandocå·¥å…·',
                'cause': 'Pandocæœªå®‰è£…æˆ–ä¸åœ¨ç³»ç»ŸPATHä¸­',
                'solutions': [
                    '1. è®¿é—® https://pandoc.org/installing.html ä¸‹è½½å®‰è£…Pandoc',
                    '2. å®‰è£…æ—¶å‹¾é€‰"Add to PATH"é€‰é¡¹',
                    '3. æˆ–åœ¨åˆå§‹åŒ–æ—¶æŒ‡å®špandocè·¯å¾„: Doc2MdConverter(pandoc_path="è·¯å¾„")',
                    '4. éªŒè¯å®‰è£…: åœ¨å‘½ä»¤è¡Œè¿è¡Œ pandoc --version'
                ],
                'severity': 'critical',
                'auto_fixable': False
            },
            'file_not_found': {
                'problem': 'è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨',
                'cause': 'æŒ‡å®šçš„æ–‡ä»¶è·¯å¾„é”™è¯¯æˆ–æ–‡ä»¶å·²è¢«ç§»åŠ¨/åˆ é™¤',
                'solutions': [
                    '1. æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®',
                    '2. ç¡®è®¤æ–‡ä»¶æ‰©å±•åæ˜¯.docæˆ–.docx',
                    '3. ä½¿ç”¨ç»å¯¹è·¯å¾„è€Œéç›¸å¯¹è·¯å¾„',
                    f'4. å½“å‰å°è¯•çš„æ–‡ä»¶: {error_msg}'
                ],
                'severity': 'error',
                'auto_fixable': False
            },
            'conversion_failed': {
                'problem': 'Pandocè½¬æ¢å¤±è´¥',
                'cause': 'æ–‡æ¡£æ ¼å¼æŸåã€ç¼–ç é—®é¢˜æˆ–Pandocç‰ˆæœ¬ä¸å…¼å®¹',
                'solutions': [
                    '1. ç”¨Wordæ‰“å¼€æ–‡æ¡£å¹¶å¦å­˜ä¸ºï¼Œä¿®å¤å¯èƒ½çš„æ ¼å¼é—®é¢˜',
                    '2. å°è¯•å°†.docè½¬æ¢ä¸º.docxæ ¼å¼åå†è½¬æ¢',
                    '3. æ›´æ–°Pandocåˆ°æœ€æ–°ç‰ˆæœ¬',
                    '4. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦åŒ…å«ç‰¹æ®Šå®æˆ–åµŒå…¥å¯¹è±¡',
                    f'5. é”™è¯¯è¯¦æƒ…: {error_msg}'
                ],
                'severity': 'error',
                'auto_fixable': False
            },
            'validation_failed': {
                'problem': 'è½¬æ¢éªŒè¯å‘ç°å†…å®¹ç¼ºå¤±',
                'cause': 'è½¬æ¢è¿‡ç¨‹ä¸­æŸäº›å†…å®¹æœªèƒ½æ­£ç¡®è½¬æ¢',
                'solutions': [
                    '1. å¯¹æ¯”åŸæ–‡æ¡£å’Œè½¬æ¢åçš„Markdownæ–‡ä»¶',
                    '2. æ£€æŸ¥ç¼ºå¤±çš„å…³é”®å­—æ®µæ˜¯å¦åœ¨åŸæ–‡æ¡£ä¸­ç¡®å®å­˜åœ¨',
                    '3. é‡æ–°è½¬æ¢æ–‡æ¡£ï¼Œå¯èƒ½æ˜¯ä¸´æ—¶é—®é¢˜',
                    '4. æ‰‹åŠ¨è¡¥å……ç¼ºå¤±çš„å†…å®¹',
                    f'5. ç¼ºå¤±å†…å®¹: {error_msg}'
                ],
                'severity': 'warning',
                'auto_fixable': False
            },
            'python_docx_not_found': {
                'problem': 'æœªå®‰è£…python-docxåº“',
                'cause': 'ç¼ºå°‘æ–‡æ¡£ç»“æ„åˆ†ææ‰€éœ€çš„ä¾èµ–åº“',
                'solutions': [
                    '1. è¿è¡Œ: pip install python-docx',
                    '2. æˆ–åœ¨requirements.txtä¸­æ·»åŠ  python-docx',
                    '3. å¦‚æœä¸éœ€ç»“æ„åˆ†æï¼Œå¯å¿½ç•¥æ­¤è­¦å‘Šï¼ˆä»…å½±å“éªŒè¯åŠŸèƒ½ï¼‰'
                ],
                'severity': 'warning',
                'auto_fixable': True,
                'auto_fix_command': 'pip install python-docx'
            },
            'permission_denied': {
                'problem': 'æ–‡ä»¶è®¿é—®æƒé™ä¸è¶³',
                'cause': 'å½“å‰ç”¨æˆ·æ²¡æœ‰è¯»å–è¾“å…¥æ–‡ä»¶æˆ–å†™å…¥è¾“å‡ºç›®å½•çš„æƒé™',
                'solutions': [
                    '1. ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œå‘½ä»¤',
                    '2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«å…¶ä»–ç¨‹åºå ç”¨',
                    '3. æ›´æ¢è¾“å‡ºç›®å½•åˆ°æœ‰å†™å…¥æƒé™çš„ä½ç½®',
                    '4. åœ¨Linux/Macä¸Šä½¿ç”¨ chmod ä¿®æ”¹æƒé™'
                ],
                'severity': 'error',
                'auto_fixable': False
            }
        }
        
        if error_type in solutions:
            solution = solutions[error_type]
            print(f"\nã€é”™è¯¯è§£å†³æ–¹æ¡ˆã€‘{solution['problem']}")
            print(f"é—®é¢˜åŸå› : {solution['cause']}")
            print(f"ä¸¥é‡ç¨‹åº¦: {'ğŸ”´' if solution['severity'] == 'critical' else 'ğŸŸ ' if solution['severity'] == 'error' else 'ğŸŸ¡'} {solution['severity']}")
            print(f"\nè§£å†³æ–¹æ¡ˆ:")
            for sol in solution['solutions']:
                print(f"  {sol}")
            
            if solution.get('auto_fixable') and solution.get('auto_fix_command'):
                print(f"\nğŸ’¡ å¯è‡ªåŠ¨ä¿®å¤ï¼Œè¿è¡Œ: {solution['auto_fix_command']}")
            
            return solution
        else:
            return {
                'problem': f'æœªçŸ¥é”™è¯¯: {error_type}',
                'cause': error_msg or 'æœªçŸ¥åŸå› ',
                'solutions': [
                    '1. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯',
                    '2. æŸ¥é˜…Pandocå®˜æ–¹æ–‡æ¡£',
                    '3. å°è¯•ç®€åŒ–æ–‡æ¡£åé‡æ–°è½¬æ¢'
                ],
                'severity': 'error',
                'auto_fixable': False
            }
    
    # ==================== åŠŸèƒ½ç‚¹7: ä¿å­˜è®°å½• ====================
    def save_conversion_log(self, result: Dict, log_type: str = 'single') -> str:
        """
        ä¿å­˜è½¬æ¢è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
        
        ã€åŠŸèƒ½ç‚¹7ã€‘ä¿å­˜è®°å½• - ä¿å­˜è½¬æ¢å†å²
        
        Args:
            result: è½¬æ¢ç»“æœå­—å…¸
            log_type: æ—¥å¿—ç±»å‹ ('single'å•æ–‡ä»¶, 'batch'æ‰¹é‡)
            
        Returns:
            str: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            
        è¯´æ˜:
            æ—¥å¿—æ–‡ä»¶ä¿å­˜åœ¨ç”¨æˆ·ç›®å½•çš„ .doc2md/logs/ ä¸‹
            æ–‡ä»¶åæ ¼å¼: conversion_YYYYMMDD.log
        """
        import json
        from datetime import datetime
        
        # ç¡®å®šæ—¥å¿—ç›®å½•
        log_dir = os.path.join(os.path.expanduser('~'), '.doc2md', 'logs')
        os.makedirs(log_dir, exist_ok=True)
        
        # ç”Ÿæˆæ—¥å¿—æ–‡ä»¶å (æŒ‰æ—¥æœŸ)
        today = datetime.now().strftime('%Y%m%d')
        log_file = os.path.join(log_dir, f'conversion_{today}.log')
        
        # æ„å»ºæ—¥å¿—æ¡ç›®
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_entry = {
            'timestamp': timestamp,
            'type': log_type,
            'result': result
        }
        
        # è¿½åŠ å†™å…¥æ—¥å¿—
        try:
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
            
            print(f"  ğŸ“ è½¬æ¢è®°å½•å·²ä¿å­˜: {log_file}")
            return log_file
        except Exception as e:
            print(f"  âš ï¸  ä¿å­˜æ—¥å¿—å¤±è´¥: {e}")
            return ""
    
    def get_conversion_history(self, days: int = 7) -> List[Dict]:
        """
        è·å–æœ€è¿‘è½¬æ¢å†å²
        
        Args:
            days: æŸ¥è¯¢æœ€è¿‘å¤šå°‘å¤©çš„è®°å½•
            
        Returns:
            List[Dict]: è½¬æ¢å†å²åˆ—è¡¨
        """
        import json
        from datetime import datetime, timedelta
        
        log_dir = os.path.join(os.path.expanduser('~'), '.doc2md', 'logs')
        if not os.path.exists(log_dir):
            return []
        
        history = []
        cutoff_date = datetime.now() - timedelta(days=days)
        
        # éå†æ—¥å¿—æ–‡ä»¶
        for filename in os.listdir(log_dir):
            if filename.startswith('conversion_') and filename.endswith('.log'):
                file_path = os.path.join(log_dir, filename)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        for line in f:
                            try:
                                entry = json.loads(line.strip())
                                entry_time = datetime.strptime(
                                    entry['timestamp'], '%Y-%m-%d %H:%M:%S'
                                )
                                if entry_time >= cutoff_date:
                                    history.append(entry)
                            except:
                                continue
                except Exception as e:
                    print(f"è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥ {filename}: {e}")
        
        # æŒ‰æ—¶é—´æ’åº
        history.sort(key=lambda x: x['timestamp'], reverse=True)
        return history


# ä¾¿æ·å‡½æ•°
def doc2md(input_file: str, output_file: Optional[str] = None) -> Dict:
    """
    ä¾¿æ·å‡½æ•°ï¼šå°†Wordæ–‡æ¡£è½¬æ¢ä¸ºMarkdown
    
    ä½¿ç”¨ç¤ºä¾‹:
        result = doc2md("éœ€æ±‚æ–‡æ¡£.docx")
        result = doc2md("éœ€æ±‚æ–‡æ¡£.docx", "è¾“å‡º.md")
    """
    converter = Doc2MdConverter()
    return converter.convert(input_file, output_file)


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("="*70)
        print("Doc2Md Converter - Wordæ–‡æ¡£è½¬Markdownå·¥å…·")
        print("="*70)
        print("")
        print("ç”¨æ³•:")
        print("  python doc2md_converter.py <è¾“å…¥æ–‡ä»¶.docx> [è¾“å‡ºæ–‡ä»¶.md]")
        print("")
        print("ç¤ºä¾‹:")
        print('  python doc2md_converter.py "éœ€æ±‚æ–‡æ¡£.docx"')
        print('  python doc2md_converter.py "éœ€æ±‚æ–‡æ¡£.docx" "è¾“å‡º.md"')
        print("="*70)
        sys.exit(1)
    
    input_path = sys.argv[1]
    output_path = sys.argv[2] if len(sys.argv) > 2 else None
    
    result = doc2md(input_path, output_path)
    
    sys.exit(0 if result.get('success') else 1)
