# OpenRouter 免费大模型分析报告

**创建时间**: 2026-02-11 10:25:28
**数据来源**: OpenRouter API
**免费模型总数**: 32个

---

## 一、核心概念解释

### 1.1 上下文长度（Context Length）是什么？

**上下文长度 = 一次对话能处理的总信息量**

```
上下文 = 你的输入 + 我的输出 + 历史对话
         ↓        ↓        ↓
      (prompt) (completion) (之前的消息)
```

| 类型 | 说明 |
|------|------|
| **不是** | 模型的"永久记忆"长度 |
| **是** | 一次会话中能处理的总信息量 |
| **包含** | 当前输入 + 历史消息 + 模型输出 |
| **用完** | 超出后最早的消息会被"遗忘" |

**举例（200K上下文）**:
```
第1轮: 用户输入100字 + 我回复200字 = 占用300字
第2轮: 累计300字 + 新输入100字 + 新回复200字 = 600字
...
第N轮: 累计接近200K时，最早的消息会被丢弃
```

**结论**: 上下文长度 = 一次会话的"短期记忆容量"，不是永久存储。

---

### 1.2 Agent 能力维度说明

从 Agent（智能代理）角度，大模型有以下关键能力：

| 能力维度 | 说明 | 重要性 |
|---------|------|--------|
| **理解能力** | 理解用户意图、代码、文档的能力 | ⭐⭐⭐⭐⭐ |
| **编程能力** | 代码生成、调试、重构能力 | ⭐⭐⭐⭐⭐ |
| **规划能力** | 任务分解、步骤规划、优先级判断 | ⭐⭐⭐⭐ |
| **工具调用** | 调用外部工具、API、执行命令的能力 | ⭐⭐⭐⭐ |
| **上下文长度** | 一次能处理的信息量上限 | ⭐⭐⭐⭐ |
| **推理能力** | 逻辑推理、复杂问题分析能力 | ⭐⭐⭐⭐ |
| **设计能力** | UI/UX设计、架构设计能力 | ⭐⭐⭐ |
| **检查能力** | 自我检查、验证结果正确性的能力 | ⭐⭐⭐ |
| **多智能体协作** | 与其他Agent协调工作的能力 | ⭐⭐ |

---

### 1.3 多智能体协作说明

**用户疑问**: 大模型是否内置多个不同能力的Agent？

**解答**:

| 模式 | 说明 | 示例 |
|------|------|------|
| **单Agent模式** | 一个大模型完成所有任务 | 当前大多数免费模型 |
| **内置多角色** | 模型内部模拟不同角色协作 | 部分高级模型 |
| **外部协作** | 多个大模型通过框架协调工作 | AutoGen, CrewAI, LangGraph |

**实际工作方式**:
```
┌─────────────────────────────────────────┐
│           外部协调框架                    │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐   │
│  │ Agent A │ │ Agent B │ │ Agent C │   │
│  │(规划者) │ │(执行者) │ │(检查者) │   │
│  └────┬────┘ └────┬────┘ └────┬────┘   │
│       │           │           │         │
│       └───────────┼───────────┘         │
│                   ↓                     │
│            共享上下文/消息队列            │
└─────────────────────────────────────────┘
```

**当前 Pony Alpha**: 单Agent模式，具备理解、编程、规划、工具调用等综合能力。

---

## 二、完整模型列表

### 2.1 免费模型总览（按上下文长度排序）

> **说明**: OpenRouter API的`stats`字段为空，不提供调用量统计数据。

| 序号 | 模型名称 | 上下文 | 最大输出 | 入驻日期 | 工具 | 推理 | 结构化 | 审核 |
|:----:|----------|------:|-------:|:--------:|:----:|:----:|:------:|:----:|
| 1 | Qwen: Qwen3 Next 80B | 262K | - | 2025-09-12 | ✅ | ❌ | ✅ | ❌ |
| 2 | Qwen: Qwen3 Coder 480B | 262K | 262K | 2025-07-23 | ✅ | ❌ | ❌ | ❌ |
| 3 | StepFun: Step 3.5 Flash | 256K | 256K | 2026-01-30 | ✅ | ✅ | ❌ | ❌ |
| 4 | NVIDIA: Nemotron 3 Nano 30B | 256K | - | 2025-12-15 | ✅ | ✅ | ❌ | ❌ |
| 5 | Pony Alpha ⭐ | 200K | 131K | 2026-02-07 | ✅ | ✅ | ✅ | ❌ |
| 6 | Free Models Router | 200K | - | 2026-02-01 | ✅ | ✅ | ✅ | ❌ |
| 7 | TNG: R1T Chimera | 163K | 65K | 2025-11-27 | ✅ | ✅ | ✅ | ❌ |
| 8 | TNG: DeepSeek R1T2 Chimera | 163K | - | 2025-07-08 | ❌ | ✅ | ❌ | ❌ |
| 9 | DeepSeek: R1 0528 | 163K | 163K | 2025-05-29 | ❌ | ✅ | ❌ | ❌ |
| 10 | TNG: DeepSeek R1T Chimera | 163K | - | 2025-04-27 | ❌ | ✅ | ❌ | ❌ |
| 11 | Arcee AI: Trinity Mini | 131K | - | 2025-12-01 | ✅ | ✅ | ✅ | ❌ |
| 12 | OpenAI: gpt-oss-120b | 131K | 131K | 2025-08-06 | ✅ | ✅ | ❌ | ✅ |
| 13 | OpenAI: gpt-oss-20b | 131K | 131K | 2025-08-06 | ✅ | ✅ | ❌ | ✅ |
| 14 | Z.AI: GLM 4.5 Air | 131K | 96K | 2025-07-26 | ✅ | ✅ | ❌ | ❌ |
| 15 | Google: Gemma 3 27B | 131K | 8K | 2025-03-12 | ✅ | ❌ | ✅ | ❌ |
| 16 | Meta: Llama 3.2 3B | 131K | - | 2024-09-25 | ❌ | ❌ | ❌ | ❌ |
| 17 | Nous: Hermes 3 405B | 131K | - | 2024-08-16 | ❌ | ❌ | ❌ | ❌ |
| 18 | Arcee AI: Trinity Large | 131K | - | 2026-01-28 | ✅ | ❌ | ✅ | ❌ |
| 19 | Aurora Alpha | 128K | 50K | 2026-02-09 | ✅ | ✅ | ✅ | ❌ |
| 20 | Upstage: Solar Pro 3 | 128K | - | 2026-01-27 | ✅ | ✅ | ✅ | ❌ |
| 21 | NVIDIA: Nemotron Nano 12B VL | 128K | 128K | 2025-10-29 | ✅ | ✅ | ❌ | ❌ |
| 22 | NVIDIA: Nemotron Nano 9B V2 | 128K | - | 2025-09-06 | ✅ | ✅ | ✅ | ❌ |
| 23 | Mistral: Small 3.1 24B | 128K | - | 2025-03-18 | ✅ | ❌ | ✅ | ❌ |
| 24 | Meta: Llama 3.3 70B | 128K | 128K | 2024-12-07 | ✅ | ❌ | ❌ | ✅ |
| 25 | Qwen: Qwen3 4B | 40K | - | 2025-05-01 | ✅ | ✅ | ✅ | ❌ |
| 26 | LiquidAI: LFM2.5-1.2B-Thinking | 32K | - | 2026-01-21 | ❌ | ✅ | ❌ | ❌ |
| 27 | LiquidAI: LFM2.5-1.2B-Instruct | 32K | - | 2026-01-21 | ❌ | ❌ | ❌ | ❌ |
| 28 | Venice: Uncensored | 32K | - | 2025-07-10 | ❌ | ❌ | ✅ | ❌ |
| 29 | Google: Gemma 3 4B | 32K | 8K | 2025-03-14 | ❌ | ❌ | ✅ | ❌ |
| 30 | Google: Gemma 3 12B | 32K | 8K | 2025-03-14 | ❌ | ❌ | ❌ | ❌ |
| 31 | Google: Gemma 3n 2B | 8K | 2K | 2025-07-09 | ❌ | ❌ | ✅ | ❌ |
| 32 | Google: Gemma 3n 4B | 8K | 2K | 2025-05-21 | ❌ | ❌ | ✅ | ❌ |

**字段说明**:
| 字段 | 说明 |
|------|------|
| **上下文** | 一次会话能处理的最大信息量 |
| **最大输出** | 单次回复最大长度（"-"表示未指定） |
| **工具** | 是否支持Function Calling/工具调用 |
| **推理** | 是否支持深度推理模式 |
| **结构化** | 是否支持结构化输出（JSON Schema等） |
| **审核** | 是否有内容审查机制 |

---

## 三、能力排名

### 3.1 上下文长度排名 Top 10

| 排名 | 模型 | 入驻日期 | 上下文 | 适用场景 |
|:----:|------|:--------:|------:|----------|
| 1 | Qwen: Qwen3 Next 80B | 2025-09-12 | 262K | 长文档处理 |
| 2 | Qwen: Qwen3 Coder 480B | 2025-07-23 | 262K | 大型代码库分析 |
| 3 | StepFun: Step 3.5 Flash | 2026-01-30 | 256K | 长文本理解 |
| 4 | NVIDIA: Nemotron 3 Nano 30B | 2025-12-15 | 256K | 超长对话 |
| 5 | Pony Alpha | 2026-02-07 | 200K | 通用编程 |
| 6 | Free Models Router | 2026-02-01 | 200K | 自动选择 |
| 7 | TNG: R1T Chimera | 2025-11-27 | 163K | 推理任务 |
| 8 | DeepSeek: R1 0528 | 2025-05-29 | 163K | 深度推理 |
| 9 | Llama 3.3 70B | 2024-12-07 | 128K | 通用对话 |
| 10 | Mistral Small 3.1 | 2025-03-18 | 128K | 欧洲开源 |

---

### 3.2 编程能力推荐排名

| 排名 | 模型 | 入驻日期 | 上下文 | 理由 |
|:----:|------|:--------:|------:|------|
| 1 | Qwen: Qwen3 Coder 480B | 2025-07-23 | 262K | 专为代码优化，超长上下文 |
| 2 | Pony Alpha | 2026-02-07 | 200K | 综合编程能力强，支持工具调用 |
| 3 | DeepSeek: R1 0528 | 2025-05-29 | 163K | 推理+编程能力突出 |
| 4 | OpenAI: gpt-oss-120b | 2025-08-06 | 131K | OpenAI开源，代码能力稳定 |
| 5 | Meta: Llama 3.3 70B | 2024-12-07 | 128K | 大参数，通用编程能力好 |

---

### 3.3 推理能力推荐排名

| 排名 | 模型 | 入驻日期 | 上下文 | 理由 |
|:----:|------|:--------:|------:|------|
| 1 | DeepSeek: R1 0528 | 2025-05-29 | 163K | DeepSeek R1系列主打推理 |
| 2 | TNG: R1T Chimera | 2025-11-27 | 163K | DeepSeek R1变体优化版 |
| 3 | Nous: Hermes 3 405B | 2024-08-16 | 131K | 405B参数，推理能力强 |
| 4 | Qwen: Qwen3 Next 80B | 2025-09-12 | 262K | 通义千问高级推理 |
| 5 | Pony Alpha | 2026-02-07 | 200K | 综合推理能力均衡 |

---

### 3.4 中文能力推荐排名

| 排名 | 模型 | 入驻日期 | 上下文 | 理由 |
|:----:|------|:--------:|------:|------|
| 1 | Qwen: Qwen3 Next 80B | 2025-09-12 | 262K | 阿里通义千问，中文优化 |
| 2 | DeepSeek: R1 0528 | 2025-05-29 | 163K | 国产模型，中文能力强 |
| 3 | Z.AI: GLM 4.5 Air | 2025-07-26 | 131K | 智谱GLM，中文优化 |
| 4 | StepFun: Step 3.5 Flash | 2026-01-30 | 256K | 阶跃星辰，国产模型 |
| 5 | Pony Alpha | 2026-02-07 | 200K | 综合能力，中文支持良好 |

---

### 3.5 Agent工作流适用排名

| 排名 | 模型 | 入驻日期 | 上下文 | 理由 |
|:----:|------|:--------:|------:|------|
| 1 | Pony Alpha | 2026-02-07 | 200K | 专为Agentic工作流设计，支持工具调用 |
| 2 | Aurora Alpha | 2026-02-09 | 128K | 推理模型，适合代理任务 |
| 3 | StepFun: Step 3.5 Flash | 2026-01-30 | 256K | 支持推理+工具，超长上下文 |
| 4 | Qwen: Qwen3 Coder 480B | 2025-07-23 | 262K | 长上下文+工具调用，适合代码代理 |
| 5 | Free Models Router | 2026-02-01 | 200K | 自动选择最佳免费模型 |

---

## 四、按厂商分类

| 厂商 | 免费模型数 | 代表模型 | 特点 |
|------|:--------:|----------|------|
| **Qwen/阿里** | 3 | Qwen3 Coder 480B | 中文优化，代码能力强 |
| **NVIDIA** | 3 | Nemotron 3 Nano 30B | 超长上下文256K |
| **Google** | 5 | Gemma 3 27B | 开源生态丰富 |
| **TNG** | 3 | R1T Chimera | DeepSeek推理变体 |
| **OpenRouter** | 3 | Pony Alpha | 综合能力强 |
| **Meta** | 2 | Llama 3.3 70B | 社区活跃 |
| **OpenAI** | 2 | gpt-oss-120b | OpenAI开源 |
| **其他** | 11 | 各1个 | 多样化选择 |

---

## 五、使用场景推荐

| 使用场景 | 推荐模型 | 模型ID | 理由 |
|---------|---------|--------|------|
| **日常编程** | Pony Alpha | `openrouter/pony-alpha` | 200K上下文，综合能力强 |
| **大型代码分析** | Qwen3 Coder | `qwen/qwen3-coder:free` | 262K上下文，代码专用 |
| **深度推理** | DeepSeek R1 | `deepseek/deepseek-r1-0528:free` | 推理能力突出 |
| **大模型体验** | Hermes 3 405B | `nousresearch/hermes-3-llama-3.1-405b:free` | 405B最大参数 |
| **快速响应** | Gemma 3n 2B | `google/gemma-3n-e2b-it:free` | 2B参数，速度最快 |
| **中文对话** | Qwen3 Next | `qwen/qwen3-next-80b-a3b-instruct:free` | 中文能力强 |
| **长文档处理** | Step 3.5 Flash | `stepfun/step-3.5-flash:free` | 256K上下文 |
| **不确定选哪个** | Free Router | `openrouter/free` | 自动路由到可用免费模型 |

---

## 六、总结

### 6.1 关键数据

| 统计项 | 数值 |
|--------|-----:|
| 免费模型总数 | 32个 |
| 最大上下文 | 262,144 tokens |
| 最大参数 | 480B (Qwen3 Coder) |
| 最新模型 | Aurora Alpha (2026-02-09) |
| 涉及厂商 | 15+ 家 |

### 6.2 选择建议

```
编程任务 → Qwen3 Coder / Pony Alpha
推理任务 → DeepSeek R1 / R1T Chimera
中文任务 → Qwen3 / DeepSeek / GLM
长文档  → Step 3.5 Flash / Nemotron 3
不确定  → Free Models Router
```

---

**更新时间**: 2026-02-11 11:23:01
**版本**: v1.2

---

## 七、数据说明

### 7.1 API数据来源

| 项目 | 说明 |
|------|------|
| **API端点** | `https://openrouter.ai/api/v1/models` |
| **数据大小** | 463KB JSON |
| **获取时间** | 2026-02-11 |

### 7.2 数据字段说明

| 字段 | 是否可用 | 说明 |
|------|:--------:|------|
| 模型ID | ✅ | 完整可用 |
| 模型名称 | ✅ | 完整可用 |
| 上下文长度 | ✅ | 完整可用 |
| 入驻日期 | ✅ | 完整可用 |
| 最大输出 | ⚠️ | 部分模型未指定 |
| 支持参数 | ✅ | 完整可用 |
| **调用量统计** | ❌ | API不提供（stats字段为空） |

### 7.3 关于DCP Prune的说明

**用户疑问**: DCP的prune操作会不会删除获取到的数据？

**解答**:
- Prune只删除**对话上下文**中的工具输出显示
- **不会删除**实际存放在磁盘上的数据文件
- 原始API数据文件(`tool_c4a6fb58b001tcWLUvk3o9aFdx`)仍在磁盘，463KB完整保留
- 所以数据是安全的，只是对话中看不到之前的输出了
